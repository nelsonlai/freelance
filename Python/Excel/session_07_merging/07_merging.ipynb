{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Session 7: Merging and Combining\n",
        "\n",
        "Welcome to this interactive session! This notebook contains all the examples from the Python script.\n",
        "\n",
        "## ðŸ“‹ How to Use This Notebook\n",
        "\n",
        "1. Run cells sequentially using Shift+Enter\n",
        "2. Modify the code and experiment\n",
        "3. Check the output after each cell\n",
        "4. Refer to the markdown guide for detailed explanations\n",
        "\n",
        "## ðŸš€ Let's Begin!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Session 7: Merging and Combining Excel Files - Comprehensive Examples\n",
        "======================================================================\n",
        "\n",
        "This script demonstrates comprehensive techniques for merging and consolidating\n",
        "Excel files from multiple sources.\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"Session 7: Merging and Combining Excel Files\")\n",
        "print(\"=\" * 80)\n",
        "print()\n",
        "\n",
        "# Create output directory\n",
        "output_dir = Path(__file__).parent / 'sample_files'\n",
        "output_dir.mkdir(exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. CREATE SAMPLE FILES FOR MERGING\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"1. CREATING SAMPLE FILES FOR MERGING\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Create quarterly sales files\n",
        "np.random.seed(42)\n",
        "\n",
        "for quarter, months in [('Q1', ['Jan', 'Feb', 'Mar']), \n",
        "                        ('Q2', ['Apr', 'May', 'Jun']),\n",
        "                        ('Q3', ['Jul', 'Aug', 'Sep']),\n",
        "                        ('Q4', ['Oct', 'Nov', 'Dec'])]:\n",
        "    \n",
        "    data = {\n",
        "        'Product': np.random.choice(['Laptop', 'Mouse', 'Keyboard', 'Monitor'], 30),\n",
        "        'Region': np.random.choice(['North', 'South', 'East', 'West'], 30),\n",
        "        'Sales': np.random.randint(1000, 10000, 30),\n",
        "        'Quantity': np.random.randint(10, 100, 30)\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    filename = output_dir / f'{quarter}_2024.xlsx'\n",
        "    df.to_excel(filename, index=False)\n",
        "    print(f\"âœ“ Created: {filename.name}\")\n",
        "\n",
        "print()\n",
        "\n",
        "# Create regional files\n",
        "for region in ['North', 'South', 'East', 'West']:\n",
        "    data = {\n",
        "        'Date': pd.date_range('2024-01-01', periods=20, freq='D'),\n",
        "        'Product': np.random.choice(['Product A', 'Product B', 'Product C'], 20),\n",
        "        'Sales': np.random.randint(5000, 15000, 20),\n",
        "        'Region': region\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    filename = output_dir / f'{region}_region.xlsx'\n",
        "    df.to_excel(filename, index=False)\n",
        "    print(f\"âœ“ Created: {filename.name}\")\n",
        "\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. SIMPLE VERTICAL CONCATENATION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"2. SIMPLE VERTICAL CONCATENATION (STACKING)\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Read quarterly files\n",
        "df_q1 = pd.read_excel(output_dir / 'Q1_2024.xlsx')\n",
        "df_q2 = pd.read_excel(output_dir / 'Q2_2024.xlsx')\n",
        "df_q3 = pd.read_excel(output_dir / 'Q3_2024.xlsx')\n",
        "df_q4 = pd.read_excel(output_dir / 'Q4_2024.xlsx')\n",
        "\n",
        "print(f\"Q1: {len(df_q1)} rows\")\n",
        "print(f\"Q2: {len(df_q2)} rows\")\n",
        "print(f\"Q3: {len(df_q3)} rows\")\n",
        "print(f\"Q4: {len(df_q4)} rows\")\n",
        "print()\n",
        "\n",
        "# Concatenate\n",
        "df_annual = pd.concat([df_q1, df_q2, df_q3, df_q4], ignore_index=True)\n",
        "print(f\"Combined annual data: {len(df_annual)} rows\")\n",
        "print(df_annual.head())\n",
        "print()\n",
        "\n",
        "annual_file = output_dir / 'annual_2024.xlsx'\n",
        "df_annual.to_excel(annual_file, index=False)\n",
        "print(f\"âœ“ Saved: {annual_file.name}\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. CONCATENATION WITH SOURCE TRACKING\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"3. CONCATENATION WITH SOURCE TRACKING\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Add source information\n",
        "df_q1['Quarter'] = 'Q1'\n",
        "df_q2['Quarter'] = 'Q2'\n",
        "df_q3['Quarter'] = 'Q3'\n",
        "df_q4['Quarter'] = 'Q4'\n",
        "\n",
        "df_annual_tracked = pd.concat([df_q1, df_q2, df_q3, df_q4], ignore_index=True)\n",
        "print(\"Combined with quarter tracking:\")\n",
        "print(df_annual_tracked.head())\n",
        "print()\n",
        "print(\"Records per quarter:\")\n",
        "print(df_annual_tracked['Quarter'].value_counts())\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. BATCH CONCATENATION FROM DIRECTORY\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"4. BATCH CONCATENATION FROM DIRECTORY\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Find all quarterly files\n",
        "quarterly_files = sorted(output_dir.glob('Q*_2024.xlsx'))\n",
        "print(f\"Found {len(quarterly_files)} quarterly files:\")\n",
        "\n",
        "dataframes = []\n",
        "for file in quarterly_files:\n",
        "    df = pd.read_excel(file)\n",
        "    df['Source_File'] = file.name\n",
        "    df['Quarter'] = file.stem.split('_')[0]\n",
        "    dataframes.append(df)\n",
        "    print(f\"  âœ“ {file.name}: {len(df)} rows\")\n",
        "\n",
        "df_all_quarters = pd.concat(dataframes, ignore_index=True)\n",
        "print(f\"\\nTotal combined: {len(df_all_quarters)} rows\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. HORIZONTAL MERGING (JOINING)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"5. HORIZONTAL MERGING (JOINING)\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Create two related datasets\n",
        "df_orders = pd.DataFrame({\n",
        "    'Order_ID': [101, 102, 103, 104, 105],\n",
        "    'Customer_ID': [1, 2, 1, 3, 4],\n",
        "    'Product': ['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Webcam'],\n",
        "    'Amount': [1000, 30, 80, 300, 90]\n",
        "})\n",
        "\n",
        "df_customers = pd.DataFrame({\n",
        "    'Customer_ID': [1, 2, 3, 4, 5],\n",
        "    'Customer_Name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],\n",
        "    'City': ['NYC', 'LA', 'Chicago', 'Houston', 'Phoenix']\n",
        "})\n",
        "\n",
        "print(\"Orders:\")\n",
        "print(df_orders)\n",
        "print(\"\\nCustomers:\")\n",
        "print(df_customers)\n",
        "print()\n",
        "\n",
        "# Inner join\n",
        "df_inner = pd.merge(df_orders, df_customers, on='Customer_ID', how='inner')\n",
        "print(\"Inner Join (only matching records):\")\n",
        "print(df_inner)\n",
        "print()\n",
        "\n",
        "# Left join\n",
        "df_left = pd.merge(df_orders, df_customers, on='Customer_ID', how='left')\n",
        "print(\"Left Join (all orders, add customer info where available):\")\n",
        "print(df_left)\n",
        "print()\n",
        "\n",
        "# Right join\n",
        "df_right = pd.merge(df_orders, df_customers, on='Customer_ID', how='right')\n",
        "print(\"Right Join (all customers, add order info where available):\")\n",
        "print(df_right)\n",
        "print()\n",
        "\n",
        "# Outer join\n",
        "df_outer = pd.merge(df_orders, df_customers, on='Customer_ID', how='outer')\n",
        "print(\"Outer Join (all records from both):\")\n",
        "print(df_outer)\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. MERGING WITH DIFFERENT COLUMN NAMES\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"6. MERGING WITH DIFFERENT COLUMN NAMES\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Datasets with different key column names\n",
        "df_employees = pd.DataFrame({\n",
        "    'EmpID': [101, 102, 103],\n",
        "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
        "    'Department': ['Sales', 'IT', 'HR']\n",
        "})\n",
        "\n",
        "df_salaries = pd.DataFrame({\n",
        "    'EmployeeID': [101, 102, 103],\n",
        "    'Salary': [60000, 75000, 58000],\n",
        "    'Bonus': [6000, 7500, 5800]\n",
        "})\n",
        "\n",
        "print(\"Employees:\")\n",
        "print(df_employees)\n",
        "print(\"\\nSalaries:\")\n",
        "print(df_salaries)\n",
        "print()\n",
        "\n",
        "# Merge on different column names\n",
        "df_emp_salary = pd.merge(\n",
        "    df_employees, df_salaries,\n",
        "    left_on='EmpID',\n",
        "    right_on='EmployeeID',\n",
        "    how='inner'\n",
        ")\n",
        "print(\"Merged (on different column names):\")\n",
        "print(df_emp_salary)\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. MERGING MULTIPLE FILES\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"7. MERGING ALL REGIONAL FILES\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Find all regional files\n",
        "regional_files = sorted(output_dir.glob('*_region.xlsx'))\n",
        "print(f\"Found {len(regional_files)} regional files:\")\n",
        "\n",
        "regional_dataframes = []\n",
        "for file in regional_files:\n",
        "    df = pd.read_excel(file)\n",
        "    print(f\"  âœ“ {file.name}: {len(df)} rows\")\n",
        "    regional_dataframes.append(df)\n",
        "\n",
        "df_national = pd.concat(regional_dataframes, ignore_index=True)\n",
        "print(f\"\\nNational dataset: {len(df_national)} rows\")\n",
        "print(df_national.head(10))\n",
        "print()\n",
        "\n",
        "national_file = output_dir / 'national_sales.xlsx'\n",
        "df_national.to_excel(national_file, index=False)\n",
        "print(f\"âœ“ Saved: {national_file.name}\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. CONSOLIDATING WITH AGGREGATION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"8. CONSOLIDATING WITH AGGREGATION\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Aggregate quarterly data\n",
        "quarterly_summary = df_all_quarters.groupby('Quarter').agg({\n",
        "    'Sales': 'sum',\n",
        "    'Quantity': 'sum'\n",
        "}).round(2)\n",
        "\n",
        "print(\"Quarterly Summary:\")\n",
        "print(quarterly_summary)\n",
        "print()\n",
        "\n",
        "# Product performance across all quarters\n",
        "product_summary = df_all_quarters.groupby('Product').agg({\n",
        "    'Sales': ['sum', 'mean', 'count'],\n",
        "    'Quantity': 'sum'\n",
        "}).round(2)\n",
        "\n",
        "print(\"Product Performance:\")\n",
        "print(product_summary)\n",
        "print()\n",
        "\n",
        "# Regional performance\n",
        "regional_summary = df_all_quarters.groupby('Region').agg({\n",
        "    'Sales': 'sum',\n",
        "    'Quantity': 'sum'\n",
        "}).sort_values('Sales', ascending=False)\n",
        "\n",
        "print(\"Regional Performance:\")\n",
        "print(regional_summary)\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. PIVOT TABLE FROM MERGED DATA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"9. PIVOT TABLE FROM MERGED DATA\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Create pivot table\n",
        "pivot_sales = pd.pivot_table(\n",
        "    df_all_quarters,\n",
        "    values='Sales',\n",
        "    index='Product',\n",
        "    columns='Quarter',\n",
        "    aggfunc='sum',\n",
        "    fill_value=0\n",
        ")\n",
        "\n",
        "print(\"Sales by Product and Quarter:\")\n",
        "print(pivot_sales)\n",
        "print()\n",
        "\n",
        "# Regional quarterly pivot\n",
        "pivot_regional = pd.pivot_table(\n",
        "    df_all_quarters,\n",
        "    values='Sales',\n",
        "    index='Region',\n",
        "    columns='Quarter',\n",
        "    aggfunc='sum',\n",
        "    fill_value=0\n",
        ")\n",
        "\n",
        "print(\"Sales by Region and Quarter:\")\n",
        "print(pivot_regional)\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. COMPREHENSIVE CONSOLIDATION REPORT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"10. COMPREHENSIVE CONSOLIDATION REPORT\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Create comprehensive report with multiple sheets\n",
        "report_file = output_dir / 'consolidation_report.xlsx'\n",
        "\n",
        "with pd.ExcelWriter(report_file, engine='openpyxl') as writer:\n",
        "    # Raw data\n",
        "    df_all_quarters.to_excel(writer, sheet_name='All_Data', index=False)\n",
        "    \n",
        "    # Summaries\n",
        "    quarterly_summary.to_excel(writer, sheet_name='Quarterly_Summary')\n",
        "    product_summary.to_excel(writer, sheet_name='Product_Analysis')\n",
        "    regional_summary.to_excel(writer, sheet_name='Regional_Performance')\n",
        "    \n",
        "    # Pivots\n",
        "    pivot_sales.to_excel(writer, sheet_name='Product_Quarterly')\n",
        "    pivot_regional.to_excel(writer, sheet_name='Regional_Quarterly')\n",
        "    \n",
        "    # National data\n",
        "    df_national.to_excel(writer, sheet_name='National_Data', index=False)\n",
        "\n",
        "print(f\"âœ“ Created comprehensive report: {report_file.name}\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. HANDLING DIFFERENT STRUCTURES\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"11. HANDLING DIFFERENT STRUCTURES\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Create files with different structures\n",
        "df_file1 = pd.DataFrame({\n",
        "    'ID': [1, 2, 3],\n",
        "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
        "    'Value': [100, 200, 300]\n",
        "})\n",
        "\n",
        "df_file2 = pd.DataFrame({\n",
        "    'ID': [4, 5, 6],\n",
        "    'Name': ['Diana', 'Eve', 'Frank'],\n",
        "    'Value': [400, 500, 600],\n",
        "    'Extra': ['X', 'Y', 'Z']  # Extra column\n",
        "})\n",
        "\n",
        "print(\"File 1 columns:\", df_file1.columns.tolist())\n",
        "print(\"File 2 columns:\", df_file2.columns.tolist())\n",
        "print()\n",
        "\n",
        "# Concatenate (missing columns filled with NaN)\n",
        "df_combined = pd.concat([df_file1, df_file2], ignore_index=True)\n",
        "print(\"Combined (Extra column has NaN for File 1):\")\n",
        "print(df_combined)\n",
        "print()\n",
        "\n",
        "# Fill missing values\n",
        "df_combined['Extra'] = df_combined['Extra'].fillna('N/A')\n",
        "print(\"After filling missing values:\")\n",
        "print(df_combined)\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. ERROR-SAFE MERGING FUNCTION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"12. ERROR-SAFE MERGING FUNCTION\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "def safe_merge_files(directory, pattern='*.xlsx', output='merged.xlsx'):\n",
        "    \"\"\"\n",
        "    Safely merge multiple files with error handling\n",
        "    \"\"\"\n",
        "    try:\n",
        "        files = list(Path(directory).glob(pattern))\n",
        "        if not files:\n",
        "            print(f\"No files found matching {pattern}\")\n",
        "            return False\n",
        "        \n",
        "        print(f\"Found {len(files)} files to merge:\")\n",
        "        \n",
        "        dataframes = []\n",
        "        failed_files = []\n",
        "        \n",
        "        for file in files:\n",
        "            try:\n",
        "                df = pd.read_excel(file)\n",
        "                if df.empty:\n",
        "                    print(f\"  âš  {file.name}: empty, skipping\")\n",
        "                    continue\n",
        "                \n",
        "                df['Source_File'] = file.name\n",
        "                df['Merge_Date'] = datetime.now()\n",
        "                dataframes.append(df)\n",
        "                print(f\"  âœ“ {file.name}: {len(df)} rows\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"  âœ— {file.name}: {e}\")\n",
        "                failed_files.append((file.name, str(e)))\n",
        "        \n",
        "        if not dataframes:\n",
        "            print(\"No valid files to merge\")\n",
        "            return False\n",
        "        \n",
        "        # Merge\n",
        "        df_merged = pd.concat(dataframes, ignore_index=True)\n",
        "        print(f\"\\nâœ“ Merged {len(dataframes)} files: {len(df_merged)} total rows\")\n",
        "        \n",
        "        # Save\n",
        "        output_path = Path(directory) / output\n",
        "        df_merged.to_excel(output_path, index=False)\n",
        "        print(f\"âœ“ Saved to: {output}\")\n",
        "        \n",
        "        if failed_files:\n",
        "            print(f\"\\nâš  Failed files ({len(failed_files)}):\")\n",
        "            for filename, error in failed_files:\n",
        "                print(f\"  - {filename}: {error}\")\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Fatal error: {e}\")\n",
        "        return False\n",
        "\n",
        "# Test the function\n",
        "print(\"\\nTesting safe merge function:\")\n",
        "success = safe_merge_files(output_dir, pattern='Q*_2024.xlsx', output='safe_merged.xlsx')\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. REAL-WORLD EXAMPLE: MULTI-DEPARTMENT CONSOLIDATION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"13. REAL-WORLD EXAMPLE: MULTI-DEPARTMENT CONSOLIDATION\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Simulate department reports\n",
        "departments = ['Sales', 'Marketing', 'IT', 'HR']\n",
        "dept_files = {}\n",
        "\n",
        "for dept in departments:\n",
        "    data = {\n",
        "        'Employee': [f'{dept}_Emp_{i}' for i in range(1, 6)],\n",
        "        'Department': dept,\n",
        "        'Budget': np.random.randint(50000, 150000, 5),\n",
        "        'Actual': np.random.randint(40000, 140000, 5)\n",
        "    }\n",
        "    df_dept = pd.DataFrame(data)\n",
        "    dept_file = output_dir / f'{dept}_budget.xlsx'\n",
        "    df_dept.to_excel(dept_file, index=False)\n",
        "    dept_files[dept] = dept_file\n",
        "    print(f\"âœ“ Created {dept} budget file\")\n",
        "\n",
        "# Consolidate all department budgets\n",
        "dept_dataframes = []\n",
        "for dept, file in dept_files.items():\n",
        "    df = pd.read_excel(file)\n",
        "    dept_dataframes.append(df)\n",
        "\n",
        "df_company_budget = pd.concat(dept_dataframes, ignore_index=True)\n",
        "df_company_budget['Variance'] = df_company_budget['Budget'] - df_company_budget['Actual']\n",
        "df_company_budget['Variance_%'] = (df_company_budget['Variance'] / df_company_budget['Budget'] * 100).round(1)\n",
        "\n",
        "print(f\"\\nConsolidated company budget: {len(df_company_budget)} employees\")\n",
        "print(df_company_budget.head(10))\n",
        "print()\n",
        "\n",
        "# Department summary\n",
        "dept_summary = df_company_budget.groupby('Department').agg({\n",
        "    'Budget': 'sum',\n",
        "    'Actual': 'sum',\n",
        "    'Variance': 'sum'\n",
        "}).round(2)\n",
        "\n",
        "print(\"Department Budget Summary:\")\n",
        "print(dept_summary)\n",
        "print()\n",
        "\n",
        "# Save consolidated budget\n",
        "budget_report = output_dir / 'company_budget_consolidated.xlsx'\n",
        "with pd.ExcelWriter(budget_report, engine='openpyxl') as writer:\n",
        "    df_company_budget.to_excel(writer, sheet_name='All_Employees', index=False)\n",
        "    dept_summary.to_excel(writer, sheet_name='Department_Summary')\n",
        "\n",
        "print(f\"âœ“ Saved: {budget_report.name}\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"SESSION 7 COMPLETE!\")\n",
        "print(\"=\" * 80)\n",
        "print()\n",
        "print(\"What you learned:\")\n",
        "print(\"âœ“ Vertical concatenation (stacking files)\")\n",
        "print(\"âœ“ Horizontal merging (joining related data)\")\n",
        "print(\"âœ“ Track source files during merging\")\n",
        "print(\"âœ“ Batch process entire directories\")\n",
        "print(\"âœ“ Handle different file structures\")\n",
        "print(\"âœ“ Create aggregated summaries\")\n",
        "print(\"âœ“ Build pivot tables from merged data\")\n",
        "print(\"âœ“ Generate comprehensive reports\")\n",
        "print(\"âœ“ Implement error-safe merging\")\n",
        "print(\"âœ“ Consolidate multi-department data\")\n",
        "print()\n",
        "print(\"Files created:\")\n",
        "for file in sorted(output_dir.glob('*.xlsx')):\n",
        "    print(f\"  - {file.name}\")\n",
        "print()\n",
        "print(\"Next: Session 8 - Advanced Data Operations\")\n",
        "print(\"=\" * 80)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}